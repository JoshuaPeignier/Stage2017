\documentclass[a4paper,10pt]{llncs}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}%
\usepackage{amssymb}
\usepackage{array}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{cite}
\usepackage{color}
\usepackage{makecell}
%\usepackage{amsthm}
%opening
\title{}
\author{}

% \newtheorem{definition}{Definition}
% \newtheorem{proposition}{Proposition}
% \newtheorem{corollary}{Corollary}
% \newtheorem{lemma}{Lemma}
% \newtheorem{example}{Example}
% \newtheorem{theorem}{Theorem}

\def\E {{\mathbb E}}
\def\EE {{\mathbb E}}
\def\FF {{\mathbb F}}
\def\II {{\mathbb I}}
\def\LL {{\mathbb L}}
\def\NN {{\mathbb N}}
\def\PP {{\mathbb P}}
\def\RR {{\mathbb R}}
\def\ZZ {{\mathbb Z}}
\def\RRpos {{\mathbb R_{\geq 0}}}
\def\RRposi {{\mathbb R_{\geq 0}^{\infty}}}


\definecolor{temp}{rgb}{0.8,0.4,0}
\definecolor{purple}{rgb}{0.8, 0, 0.8}
\newcommand\todo[1]{{\color{red}\textbf{[TO DO:  #1]}}}
\newcommand\idea[1]{{\color{purple}\textbf{[IDEA:  #1]}}}
\newcommand\temp[1]{{\color{temp} #1}}


\begin{document}


%\maketitle
\begin{titlepage}
 \begin{center}
  % Chercher des logos
  \includegraphics[scale=0.17]{ENS.jpg}
  \includegraphics[scale=0.17]{Rennes.png}
  \includegraphics[scale=0.4]{rwth.jpg}\\[2cm]
  %\includegraphics[scale=0.5]{rwth.jpg}\\[2cm]

  \textsc{\LARGE ENS Rennes - University of Rennes 1}\\[1cm]
  \textsc{\Large Internship report: Master Degree, first year}\\[3.5cm]
  %\textsc{\Large Parcours Recherche et Innovation}\\[3.5cm]
  
  
  \textnormal{\LARGE Possibility Distribution Semantics for Probabilistic Programs with Nondeterminism}\\[2cm]
  
  \textnormal{Intern: Joshua Peignier}\\
  \textnormal{Supervisors: Benjamin Kaminski, Christoph Matheja}\\
  \textnormal{Team: Software Modeling and Verification}\\
  \textnormal{Institute: RWTH Aachen University (Aachen, Germany)}\\
  \textnormal{Dates: 15/05/2017 - 11/08/2017}\\[3cm]
 \end{center}
 

\end{titlepage}

 \begin{abstract}
In contrast to ordinary programs, probabilistic programs compute a probability distribution of output states for each given input state. One benefit of adding randomness into programs is that computationally hard problems, such as matrix multiplication or leader election protocols, can be solved (on average) more efficiently. A frequently used design concept to model unknown or overly complex probability distributions is nondeterministic choice. However, having probabilistic and nondeterministic choice within the same program (or even within loops) leads to subtle semantical intricacies. The goal of this report is to capture the semantics of both concepts uniformly using possibility theory. This would allow to simplify existing weakest-precondition style calculi for reasoning about probabilistic and nondeterministic programs.
  \begin{description}
  \item[Keywords:]Fuzzy imperative languages ; Fuzzy relations ; Possibility theory ; Weakest-precondition
  \end{description}
\end{abstract}

\section{Introduction}
\label{sec:intro}
Probabilistic programs are a particular class of programs, in which probabilistic choices are involved. For instance, the simple program $\{ x := 2 \} [\frac{1}{3}] \{ x := 5 \}$ is a program that has a probability $\frac{1}{3}$ of setting the program variable $x$ to $2$, and a probability $\frac{2}{3}$ of setting $x$ to $5$; it is therefore a probabilistic program. What makes this kind of program different from classical deterministic programs is that executing such a program with always the same input will not always result in the same output. Though they seem more complex than deterministic programs, probabilistic programs are useful in many ways. For example, it is simpler to solve some problems with probabilistic programs than with deterministic ones, as we can build probabilistic programs which have a better average complexity than deterministic programs (sometimes at the cost of a small probability of error). Classical examples of such programs are the quicksort algorithm, Freivalds' matrix multiplication, and some primality tests, such as the Miller-Rabin test and the Solovay-Strassen test (for positive numbers), and the Berlekamp test (for polynomials). There also exists probabilistic algorithms to solve the leader election problem. In this whole report, programs containing such choices will be called \emph{probabilistic programs}.\newline 
Besides probabilistic choice, there exists a frequently used concept in nondeterministic programs, called nondeterministic choice. One example is the following program: $\{ x := 2 \} [\!] \{ x := 5 \}$. In this example, the program will set $x$ nondeterministically to $2$, or to $5$, but we cannot assign a probability to any of these choices. More precisely, it makes no sense to assign them a probability. The nondeterministic choice is used in some programs where the outcomes of a choice are known, but making the mecanism behind the choices is either unknown, or uses overly complex probability distributions. \todo{Find a source} This instruction was first introduced by Dijkstra \cite{Dijkstra76} in the GCL language, and is used, for instance, in the model-checker Spin, to model the unpredictable behavior of a program where several choices are possible. In this whole report, programs containing such choices will be called \emph{nondeterministic programs}. Programs containing both types will be called \emph{probabilistic nondeterministic programs}, whereas programs containing none of them are \emph{deterministic programs}.\bigskip

However, two major problems arise with the use of nondeterministic choice: defining proper semantics for this instruction, and the complication arising from combination of probabilistic and nondeterministic choices in the same program. In this report, we will use the following probabilistic nondeterministic program as a guildeline example:
\begin{align*}
 P_0\textnormal{: } \{ x := 2 [\!] x := 5 \} [p] \{ x := 7 \} \textnormal{(with } p \in ]0,1[\textnormal{)}
\end{align*}

This program intuitively seems to set the program variable $x$ to $7$ with a probability $1-p$, and with a probability $p$, to set nondeterministically $x$ either to $2$ or to $5$. How can we semantically describe this program ?\bigskip

When introducing the GCL language \cite{Dijkstra76} (whose semantics allow it to generate nondeterministic programs, but not probabilistic programs), Dijkstra also introduced \emph{predicate transformer computation}, particularly the calculus of weakest precondition. This concept relies on Hoare triples: A \emph{Hoare triple} is a triple of the form $\{\psi\}P\{\varphi\}$, where $P$ is a program, and where $\psi$ and $\varphi$ are predicates respectively called \emph{precondition} and \emph{postcondition}. A Hoare triple is said to be \emph{valid} if and only if, each time that an initial state satisfies $\psi$, the final state obtained after executing $P$ satisfies $\varphi$. Thus, Dijkstra introduced the weakest preconditions: if $P$ is a program and $\varphi$ is a postcondition, then $wp[P](\varphi)$ is the weakest (in the sens of "satisfied by the most states") precondition $\psi$ making the Hoare triple $\{\psi\}P\{\varphi\}$ valid.  The predicate transformer computation is a set of rules which, knowing a program $P$ and a postcondition $\psi$, allow the computation of the associated weakest precondition $wp[P](\psi)$.\newline
For instance, consider the following program:
\begin{align*}
 P_1\textnormal{: } x := -y+1
\end{align*}
If we denote by $[x \geq 5]$ the predicate satisfied by all states where $x$ is greater or equal to $5$, then we get that $wp[P_1]([x \leq 5]) = [y \leq -4]$. (The formal method to get this result is presented in \cite{Dijkstra76} and will be reminded in Section \ref{sec:preliminaries})?\bigskip

This method was later further extended \cite{McIver05} to probabilistic programs, by changing the semantics a little, such that the weakest precondition $wp[P](\varphi)$ assigns to each state $\sigma$ the probability that the execution of the program $P$ in $\sigma$ terminates in a state satisfying $\varphi$. By applying semantics defined in \cite{McIver05} to the program $P_0$ (note that, the way the program is written, the final state should not depend on the initial state in this example), we get that the probability, for each initial state, that the the final state satisfies $[x = 7]$ is $1-p$, which is intuitively expected (formally, this means that $wp[P_0]([x = 7])$ assigns to each state the constant $1-p$). Now, consider the subprogram $P_2$ of $P_0$:
\begin{align*}
 P_2\textnormal{: } x := 2 [\!] x := 5 
\end{align*}
We also get that the probability, for each state, that the final state satisfies $[x = 2]$ is $0$ (and symmetrically for $[x = 5]$), but the probability for each state that the final state satisfies $[x = 2 \textnormal{ OR } x = 5]$ is $p$. Theses results are not unexpected, as the execution of $P_0$ has a probability $p$ of executing the $P_2$, in which we know that $x$ is set  either to $2$ or to $5$. However, as it is not possible to assign probabilities to the nondeterministic choices, conventions must be defined in order to compute weakest preconditions. In \cite{McIver05}, the authors chose a convention such that, in this case, the probability of getting to a state satisfying $[x = 2]$ is $0$, as there is no guarantee that the corresponding instruction is executed and no way to assign a probability.\newline
However, this result seems to lack information, as there is a possibility that the final state satisfies $[x = 2]$, but the corresponding probability is $0$, and in order to know that this program can achieve a state where $[x = 2]$, we have to compute the weakest precondition of another postcondition as $[x = 2]$ (in this case, $[x := 2 \textnormal{ OR } x = 5]$).\newline
Moreover, the convention chosen in \cite{McIver05} (and in \cite{WuChen11}) is not universal, as other authors \cite{WuChen08,WuChen12} chose conventions with which we get other results (notably the probability of achieving a state where $[x = 2]$ holds becomes $p$ (and symmetrically for $[x = 5]$), and the probability of achieving a state where $[x = 2 \textnormal{ OR } x = 5]$ holds remains $p$ ). \bigskip

Some authors \cite{WuChen08,WuChen11,WuChen12} tried a different approach to weakest precondition calculus, based on possibility theory rather on probabilities, in order to define different semantics and possibly give a better comprehension of how nondeterministic programs behave.
Possibility theory is an alternative approach to probabilities to model uncertainty (detailed in \cite{Agarwal15,Shapiro09}). It is well-known that $Pr$ is a probability measure over $\Omega$ for the $\sigma$-algebra $\mathcal{A}$ is a mapping $Pr$ satisfying the following axioms:
\begin{enumerate}
\item $\forall U \in \mathcal{A}$, $Pr(U) \in [0,1]$
\item $Pr(\emptyset) = 0$
\item $Pr(\Omega) = 1$
\item $\forall U,V \in \mathcal{A}$, $Pr(U \cup V) = Pr(U) + Pr(V) - Pr(U \cap V)$
\end{enumerate}
In this case, $(\Omega,\mathcal{A},\Pr)$ is a probabilistic space.\newline
On the contrary, possibility measure over $\Omega$ for the $\sigma$-algebra $\mathcal{A}$ is a mapping $\Pi$ satisfying the following axioms:
\begin{enumerate}
\item $\forall U \in \mathcal{A}$, $\Pi(U) \in [0,1]$
\item $\Pi(\emptyset) = 0$
\item $\Pi(\Omega) = 1$
\item $\forall U,V \in \mathcal{A}$, $\Pi(U \cup V) = \Max( Pi(U), \Pi(V))$
\end{enumerate}


In this report, our goal is to give our own semantics of languages including both type of choices, and more precisely an expected value semantics (which can be derived from predicate transformer semantics), where we consider expected values of fuzzy random variables (first defined in \cite{PuriRal86}, and then simplified in \cite{Shapiro09}). It is a way to combine the work in \cite{WuChen08,WuChen11,WuChen12} using possibility theory with the languages presented in \cite{McIver05}.\newline
\todo{Insert a quick organisation of the report here, reminding what to find in each section}


\section{Context and Motivation}
\label{sec:context}
\temp{
In this whole report, we will primarly consider the pGCL language, presented in \cite{McIver05}, and defined by the following grammar\footnote{The original pGCL included an \texttt{abort} instruction corresponding to an error case. We chose, not to include it, as it can be represented by $\texttt{while} (\texttt{true})\{ \texttt{skip} \}$}:


\begin{align*}
 S ::= & \texttt{ skip } \,|\, x := A \,|\, S;S \,|\, \{S\} [p] \{S\} \,|\, \{S\} [\!] \{S\} \,|\ \\
 & \texttt{ if } (b) \texttt{ then } \{ S \} \texttt{ else } \{ S \} \,|\, \texttt{ while }(b) \texttt{ do }\{S\} \\
\end{align*}

This language is sufficient to describe any probabilistic or nondeterministic program. The \texttt{if\dots then\dots else} and \texttt{while} structure are the usual control structures encountered in many languages. The \texttt{skip} instruction corresponds to an empty instruction, where nothing is done (it is included in the language so that we do not have to create a specific \texttt{if\dots then\dots} instruction for the case where no \texttt{else} is needed.) $x := A$ is an assignment statement, where the program variable $x$ is set to the value of the expression $A$ in the current state. $S_1 ; S_2$ is a sequence assignment, modeling the execution of $S_1$ followed by $S_2$. We take interest primarly in the two remaining instructions.\newline
The $\{S_1\} [p] \{S_2\}$ instruction models the fact that there is a probability $p$ that $S_1$ is executed, and a probability $1-p$ that $S_2$ is executed. Finally, the $\{S_1\} [\!] \{S_2\} $ (first introduced by Dijkstra in \cite{Dijkstra76}) is a statement that will nondeterministically execute either $S_1$ or $S_2$. The difference with the probabilistic choice is that no probability can be assigned to $S_1$ or $S_2$ because it makes no sense. This means that if $\{S_1\} [\!] \{S_2\} $ is executed a large number of times, no clear pattern should appear, whereas the execution of $S_1 [p] S_2$ a large number of times will tend to have a proportion $p$ of cases where $S_1$ is executed, and a proportion $1-p$ of cases where $S_2$ is executed.\newline
Note that we are using choice instructions with only two choices, but combination of instructions make possible the realisation of choices with any finite number (and even a countable number when using the loop) of outcomes.\bigskip

We now quickly explain Hoare triples for deterministic program. A \emph{Hoare triple} is a triple of the form $\{\psi\}P\{\varphi\}$, where $P$ is a program, and where $\psi$ and $\varphi$ are predicates respectively called \emph{precondition} and \emph{postcondition}. In the case of deterministic programs, $\psi$ and $\varphi$ can be seen as subsets of the state space $\Sigma$ (in that case, a state $\sigma$ satisfies $\psi$ (respectively $\varphi$) if and only if $\sigma \in \psi$ (respectively $\sigma \in \varphi$)). They can also be seen as mappings from $\Sigma$ to $\{0,1\}$ (in that case, a state $\sigma$ satisfies $\psi$ (respectively $\varphi$) if and only if $\psi(\sigma) = 1$ (respectively $\varphi(\sigma) = 1$)).\newline Finally, the Hoare triple $\{\psi\}P\{\varphi\}$ is said to be \emph{valid} if and only if, each time that an initial state satisfies $\psi$, the final state obtained after executing $P$ satisfies $\varphi$.  One important concept in this context is the \emph{weakest precondition} concept \cite{Dijkstra76}: $\psi$ is the weakest precondition of $\varphi$ for the program $P$ (which is denoted by $\psi = wp[P](\varphi)$ ) if $\psi$ is the largest subset of $\sigma$ such that $\{\psi\}P\{\varphi\}$ is valid (or alternatively, the largest mapping for the partial pointwise order on mappings).\bigskip

In \cite{McIver05}, an extension of this notion for probabilistic programs is presented. In this context, $\psi$ and $\varphi$ are mappings from $\Sigma$ to $[0,1]$, indicating the probability that a state satisfies the \emph{pre-} or \emph{postcondition}. In this context, $wp[P](\varphi)$ is a also a mapping from $\Sigma$ to $[0,1]$ and $wp[P](\varphi)(\sigma)$ describes the probability that the execution of $P$ in $\sigma$ results in a state satisfying $\psi$ (where $\psi(\sigma) = 1$).

Contrary to the probabilistic choice, which is used in several algorithms in order to solve a given problem with a better average complexity than deterministic algorithms, the nondeterministic choice seems to be of little interest and looks like an unnecessary complication. But this operator managed to find its way in many publications which took interest in it (\cite{WuChen08,WuChen11,WuChen12,McIver05}), as it can be used in some situations, where a choice has to be made, where the outcomes of the choice are known, but where the mecanism hiding behind the choice is unknown (in this case, we are unable to assign probabilities), or where the mecanism uses an overly complex probability distribution.\todo{example of unknown or too complex mecanism}.\newline

 \todo{apply the semantics of each paper to the guideline example P to show the problem}
}
\section{Related Work}
\label{sec:related}

\section{Preliminaries}
\label{sec:preliminaries}

\section{Contribution}
\label{sec:contribution}

In this section, we consider programs over the language presented in Section \ref{sec:context}, and our goal is to define clearer semantics for these programs as the semantics we presented before. Recall that we showed in Section \ref{sec:preliminaries} that weakest-precondition calculus could be used in order to compute expected values of random variables. Our main idea here is to combine the concept of \textit{Fuzzy random variable} (introduced in \cite{PuriRal86}, and simplified in \cite{Shapiro09}) with the computation of expected values.\newline
Let $\Sigma$ be the set of states. We consider that the variables in our programs can only take \underline{real positive} values.\footnote{This is due to constraints explained further. But note that we can implement an arbitrary real variable by two variables, one for its absolute value, and one for its sign.} We adapted the following definition from \cite{PuriRal86}.

\begin{definition}{\textnormal{(Fuzzy Random Variable)\newline}}
 A Fuzzy Random Variable (short: FRV) is a mapping $X$ from the set of states $\Sigma$ to the powerset $P(\RRposi)$. This means that, if $X$ is an FRV, then for all $\sigma \in \Sigma$, $X(\sigma)$ is a subset of $\RRposi$. In fact, it is a set of possible values for $X$ in the state $\sigma$.
\end{definition}
\begin{example}
 In the following, for each program variable $x$, we denote by $\underline{x}$ the FRV such that, for all $\sigma \in \Sigma$, $\underline{x}(\sigma) = \{ x_{\sigma} \}$, meaning that $\underline{x}$ associates to each state $\sigma$ the singleton containing the value $x_\sigma$, which is the value of the program variable $x$ in the set $\sigma$. (Recall that each state is characterized uniquely by a tuple containing the values of each variable in a given order.). Therefore, we can say that the FRV $\underline{x}$ models the program variable $x$.
\end{example}

A fuzzy random variable $X$ over a program can model several concepts. For instance, it can be used to model the runtime of a program executed in a state $\sigma$ (which is why we chose to include $\infty$); in this example, $X(\sigma)$ would give all possible runtimes for the execution of one program starting from $\sigma$. It can also model the value of a program variable (or any function over the program variables) after the execution of a program.\newline
% For instance, for any program variable $x$, with the previous notations, for all $\sigma \in \Sigma$, $\underline{x}(\sigma) = \{ x \}$ is the expected value of the program variable $x$ after executing the program $\texttt{skip}$ in $\sigma$.\newline
% As all previous computations can be obtained from program variables (for instance, the runtime of a program (in the sense of "number of instructions executed before termination") can be obtained by adding a program variable $t$ representing the current runtime, initially $0$, and incrementing it at each instruction), we will in the following only consider computation of expected values of fuzzy random variables characterizing the value of a program variable after the execution of the program in one state.\newline

Let $F = \{f \,|\, f : \sigma \rightarrow P(\RRposi) \}$ be the set of fuzzy random variables, and $Progs$ be the set of pGCL programs. We define the following application:

\begin{definition}
 $ev : (Progs) \rightarrow (F \rightarrow F)$ is an application mapping each program $S$ to its FRV transformer semantics. This means that, for all $S \in Progs$, $ev[S]$ transforms a FRV $X \in F$ in another FRV $ev[S](X)$.
\end{definition}
Concretely, if $X$ is a FRV (i.e. an application mapping each state $\sigma$ to a subset $X(\sigma)$ of $\RRposi$), then $ev[S](X)(\sigma)$ is the set of possible expected values of the FRV $X$ after executing $S$ in the state $\sigma$.\newline
For instance, if we consider a program variable $x$, then the FRV $\underline{x}$ maps each state $\sigma$ to the set $\{x_\sigma\}$. Our goal is that the FRV $\underline{x}$ is transformed by $ev[S]$ into the FRV $ev[S](\underline{x})$, which maps each $\sigma$ to the set $ev[S](\underline{x})(\sigma)$ of possible values of the variable $x$ after executing $S$ in the state $\sigma$. Therefore, we can say that $ev[S](\underline{x})(\sigma)$ is the \emph{expected value} (or rather \emph{set of possible expected values}) of the FRV $\underline{x}$ after executing $S$ in the state $\sigma$; or, with other words, the set of possible expected values of the program variable $x$ after executing $S$ in $\sigma$.\newline


We give rules in Table \ref{table:rules_ev} of a predicate-transformer-style calculus for the computation of expected values.\newline
\begin{table}
\begin{center}
\begin{tabular}{|p{3cm}|p{9cm}|}
 \hline
 \thead{$S$} & \thead{$ev[S](X)$} \\
 \hline
 \thead{\texttt{skip}} & \thead{$X$} \\
 \hline
 \thead{$y := A$} & \thead{$\lambda\sigma.X(\sigma[y/A])$} \\
 \hline
 \thead{$S_1 ; S_2$} & \thead{$ev[S_1](ev[S_2](X))$} \\
 \hline
 \thead{$S_1 [p] S_2$} & \thead{$\lambda\sigma.\{t_1 p+t_2(1-p) \,|\, t_1 \in ev[S_1](X)(\sigma), t_2 \in ev[S_2](X)(\sigma) \}$} \\
 \hline
 \thead{$S_1 [\!] S_2$} & \thead{$\lambda\sigma. ev[S_1](X)(\sigma) \cup ev[S_2](X)(\sigma)$} \\
 \hline
 \thead{$\texttt{if } (b) \texttt{ then } \{ S_1 \}$ \\ $\texttt{ else } \{ S_2 \}$} & \thead{$\lambda\sigma.\{[\![b : true ]\!](\sigma)\cdot t_1 + [\![b : false ]\!](\sigma)\cdot t_2 \,|\,$ \\$t_1 \in ev[S_1](X)(\sigma), t_2 \in ev[S_2](X)(\sigma) \}$} \\
 \hline
 \thead{$\texttt{while }(b) \texttt{ do }\{S\}$} & \thead{lfp ($\lambda Y. (\lambda \sigma. \{[\![b : true ]\!](\sigma)\cdot t_1 + [\![b : false ]\!](\sigma)\cdot t_2 \,|\,$\\$t_1 \in ev[S](Y)(\sigma), t_2 \in X(\sigma) \}$))} \\
 \hline
\end{tabular}
\end{center}
\label{table:rules_ev}
\caption{Rules for defining the FRV transformer $ev$}
\end{table}

Consider the guideline example $P$: $\{ x := 2 [\!] x := 5 \} [p] \{ x := 7 \}$. We want to compute the expected value of $x$ after the execution of $P$. Thus, we have to determine $ev[P](\underline{x})$,which will map each state $\sigma$ to the expected value of $x$ after executing $P$ in $\sigma$. It is a function of $\sigma$, but the form of $P$ gives the intuition that it will be a constant function, not depending on $\sigma$.\newline
With the rules presented in Table \ref{table:rules_ev}, we can see that this requires first to compute the functions $ev[x := 2 [\!] x := 5](\underline{x})$ and $ev[x := 7](\underline{x})$; besides, the former requires to compute $ev[x := 2](\underline{x})$, $ev[x := 5](\underline{x})$.\newline

We get that:
$$ev[x := 2](\underline{x}) = \lambda\sigma.\underline{x}(\sigma[x/2]) = \lambda\sigma.\{x_{\sigma[x/2]}\} = \lambda\sigma.\{2\}$$ 
Indeed, the value of $x$ in $\sigma[x/2]$ is necessarily $2$. Recall that $\sigma[x/2]$ is the state obtained after setting $x$ to $2$ in the state $\sigma$. This means that the expected value of $x$ after executing $x := 2$ in any state $\sigma$ can only be $2$. By the same computation, we get $ev[x := 5](\underline{x}) = \lambda\sigma.\{5\}$ and $ev[x := 7](\underline{x}) = \lambda\sigma.\{7\}$.\newline

Now, we can compute that:
\begin{align*}
ev[x := 2 [\!] x := 5](\underline{x}) &= \lambda\sigma. ev[x := 2](\underline{x})(\sigma) \cup ev[x := 5](\underline{x})(\sigma) \\
&= \lambda\sigma. \{2\} \cup \{5\} = \lambda\sigma.\{2,5\} 
\end{align*}
This means that the possible expected values of $x$ after executing $x := 2 [\!] x := 5$ in any state $\sigma$ are $2$ and $5$.\newline

Finally, 
\begin{align*}
ev[P](\underline{x}) &= \lambda\sigma.\{t_1 p+t_2(1-p) \,|\, t_1 \in ev[x := 2 [\!] x := 5](\underline{x})(\sigma), t_2 \in ev[x := 7](\underline{x})(\sigma) \} \\
&= \lambda\sigma.\{t_1 p+t_2(1-p) \,|\, t_1 \in \{2,5\}, t_2 \in \{7\} \} \\
&= \lambda\sigma. \{2p+7(1-p),5p+7(1-p) \} 
\end{align*}



\section{Conclusion}
\todo{Explain that, for a program $S$, by considering each of its variables $x$ and computing $ev[S](\underline{x})$, we are able to fully characterize the program $S$ and get an understanding of what it does. Explain that it is clearer than what was done before.}
\label{sec:conclusion}


\bibliography{ref1}{}
\bibliographystyle{plain}

\end{document}
